{"cells": [{"cell_type": "code", "execution_count": null, "id": "eb1df546", "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs187-2021/lab3-3.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "id": "b25ecdbb", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "raw", "id": "3003842b", "metadata": {"jupyter": {"source_hidden": true}}, "source": ["%%latex\n", "\\newcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\newcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\newcommand{\\softmax}{\\operatorname{softmax}}\n", "\\newcommand{\\Prob}{\\Pr}\n", "\\newcommand{\\given}{\\,|\\,}"]}, {"cell_type": "markdown", "id": "21f40bc0", "metadata": {"jupyter": {"source_hidden": true}}, "source": ["$$\n", "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n", "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n", "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n", "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n", "\\renewcommand{\\Prob}{\\Pr}\n", "\\renewcommand{\\given}{\\,|\\,}\n", "$$"]}, {"cell_type": "markdown", "id": "6599e602", "metadata": {"colab_type": "text", "id": "YhNwlK5J_wU_", "tags": ["remove_for_latex"]}, "source": ["# CS187\n", "## Lab 3-3 - Probabilistic context-free grammars"]}, {"cell_type": "markdown", "id": "6e463058", "metadata": {"colab_type": "text", "id": "w9cQ2kCv_zax"}, "source": ["In previous labs, you have practiced constituency parsing using context-free grammars with the CKY parsing algorithm. In this lab you will extend this framework to a probabilistic one, probabilistic context-free grammars (PCFG)."]}, {"cell_type": "markdown", "id": "6b42b589", "metadata": {}, "source": ["New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n", "\n", "* [`math.prod`](https://docs.python.org/3/library/math.html#math.prod)\n", "* [`nltk.tree.Tree.productions`](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions)"]}, {"cell_type": "markdown", "id": "13e4e5e9", "metadata": {}, "source": ["# Preparations {-}"]}, {"cell_type": "code", "execution_count": null, "id": "da45d4cf", "metadata": {"colab": {}, "colab_type": "code", "deletable": false, "editable": false, "id": "d8kPmrmwB2U9"}, "outputs": [], "source": ["import copy\n", "import math\n", "import nltk\n", "import operator\n", "import pandas as pd\n", "\n", "from collections import Counter, defaultdict\n", "from pprint import pprint"]}, {"cell_type": "markdown", "id": "51ce4209", "metadata": {"colab_type": "text", "id": "ieywAjIBFLbz"}, "source": ["# Syntactic ambiguity\n", "\n", "Let's start with the following simplified grammar for arithmetic word expressions from the last lab:"]}, {"cell_type": "code", "execution_count": null, "id": "4d065801", "metadata": {"colab": {}, "colab_type": "code", "id": "d8kPmrmwB2U9"}, "outputs": [], "source": ["arithmetic_grammar = nltk.CFG.fromstring(\"\"\"\n", "    S -> NUM | S OP S\n", "    OP -> ADD | MULT\n", "\n", "    NUM -> 'zero' | 'one' | 'two' | 'three' | 'four' | 'five'\n", "    NUM -> 'six' | 'seven' | 'eight' | 'nine' | 'ten' \n", "    \n", "    ADD -> 'plus'\n", "    MULT -> 'times'\n", "\"\"\")"]}, {"cell_type": "markdown", "id": "b1fd7948", "metadata": {}, "source": ["As a running example throughout this lab, we'll use the example phrase \"two times three plus four\"."]}, {"cell_type": "code", "execution_count": null, "id": "0a057a77", "metadata": {}, "outputs": [], "source": ["example = \"two plus three times four\""]}, {"cell_type": "markdown", "id": "d54c5d8e", "metadata": {"colab_type": "text", "id": "JIt2BY8yGIqP"}, "source": ["We can use the given CFG to parse this example phrase and print the possible parse trees."]}, {"cell_type": "code", "execution_count": null, "id": "47ff0e6b", "metadata": {"colab": {}, "colab_type": "code", "id": "SMI2sSeQLnv-"}, "outputs": [], "source": ["parser = nltk.parse.BottomUpChartParser(arithmetic_grammar)\n", "parses = list(parser.parse(example.split()))\n", "\n", "for i, tree in enumerate(parses):\n", "  print(f\"Parse {i+1}:\\n\")\n", "  tree.pretty_print()"]}, {"cell_type": "markdown", "id": "33a47756", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "v0vIENitPzq9"}, "source": ["Each parse tree represents a structured arithmetic expression (the _abstract syntax_ of the concrete expression,  for those of you with CS51 backgrounds). Manually calculate the value of the resulting equation for each of the parse trees.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parsed_equation_result\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "e1268d94", "metadata": {"colab": {}, "colab_type": "code", "id": "iEzvvFvDP77I"}, "outputs": [], "source": ["#TODO\n", "result_tree1 = ...\n", "result_tree2 = ..."]}, {"cell_type": "code", "execution_count": null, "id": "b6627085", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parsed_equation_result\")"]}, {"cell_type": "markdown", "id": "9803cc1b", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "Eqsvobh2Rx4Y"}, "source": ["We got two different parse trees for this simple expression. The occurrence of different structural interpretations of the same text is called _structural ambiguity_ or _syntactic ambiguity_. Since natural language is oftentimes ambiguous, this is a very real concern.\n", "\n", "In this particular case, the two syntactic structures corresponded to two different semantic values. As an exercise, try to construct an ambiguous expression (name it `pseudo_ambiguous`) such that all of its parse trees correspond to the same value, thereby demonstrating that not all structural ambiguity leads to semantic ambiguity.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: redundant_parses\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "f7047570", "metadata": {}, "outputs": [], "source": ["# TODO - construct an ambiguous expression such that all of its parse\n", "# trees correspond to the same value. `pseudo_ambiguous` should be\n", "# a string.\n", "pseudo_ambiguous = ..."]}, {"cell_type": "code", "execution_count": null, "id": "1f4be714", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"redundant_parses\")"]}, {"cell_type": "markdown", "id": "6d393f66", "metadata": {"colab_type": "text", "id": "Eqsvobh2Rx4Y"}, "source": ["One approach to dealing with the issue of syntactic ambiguity is by defining a scoring system to score the possible parses and choosing the highest scoring tree. We will see how this can be done by taking a probabilistic approach to CFG."]}, {"cell_type": "markdown", "id": "c4c9eef0", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "UgobxGF0WZ7V"}, "source": ["# Probabilistic context-free grammars\n", "\n", "To assign probabilities to strings, we will use a probabilistic context-free grammar (PCFG), a CFG in which each rule is augmented with a probability. A PCFG rule will be notated\n", "$$A \\to \\beta\\ [p]$$\n", "where $A$ is a nonterminal, $\\beta$ is a sequence of terminals and nonterminals, and $p$ is a probability associated with the rule.\n", "\n", "We'll write $\\Prob(\\beta \\given A)$ for the probability associated with the rule $A \\to \\beta$.\n", "\n", "To constitute a valid probability distribution we require that for every nonterminal $A$\n", "$$\\sum_{A \\to \\beta \\in \\cal{P}} \\Prob(\\beta \\given A) = 1$$\n", "where $\\cal{P}$ is the set of CFG productions of the grammar. That is, the probabilities associated with all rules with the same left-hand side must sum to one.\n", "\n", "Define `probabilistic_arithmetic_grammar` to be a probabilistic version of `arithmetic grammar` above, where the nonterminal probability distributions are **as uniform across the productions as possible**.\n", "\n", "> You'll use the NLTK `nltk.PCFG.fromstring` function, which allows you to add the probabilities in brackets after each right-hand side, just as we've been doing above. For example, to notate `NUM -> 'zero'` as of probability 0.5, use `NUM -> 'zero' [0.5]`.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: uniform_probabilities\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "99b2e6b7", "metadata": {"colab": {}, "colab_type": "code", "id": "7MMKDQ9sXNRs"}, "outputs": [], "source": ["# TODO - define `probabilistic_arithmetic_grammar`. Round to\n", "#        *3* significant figures if not divisible."]}, {"cell_type": "code", "execution_count": null, "id": "ac186ca0", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"uniform_probabilities\")"]}, {"cell_type": "markdown", "id": "7fe7f19d", "metadata": {"colab_type": "text", "id": "LJ155LVeUU9y"}, "source": ["We can use the [nltk.CFG.productions()](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.CFG.productions) method to get a list of the PCFG's productions:"]}, {"cell_type": "code", "execution_count": null, "id": "d65940ce", "metadata": {"colab": {}, "colab_type": "code", "id": "5pBrhCvNUs9m"}, "outputs": [], "source": ["probabilistic_arithmetic_grammar.productions()"]}, {"cell_type": "markdown", "id": "bc47364c", "metadata": {"colab_type": "text", "id": "Mq8J8fQxVF4Y"}, "source": ["Each of the productions in the list is an instance of the [ProbabilisticProduction](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.ProbabilisticProduction) class. Each such instance is defined by three parameters: its left hand side (`lhs`), right-hand side (`rhs`), and rule probability (`prob`). These attributes can be accessed separately:"]}, {"cell_type": "code", "execution_count": null, "id": "903d33b9", "metadata": {"colab": {}, "colab_type": "code", "id": "4TZUYEE3Vyxt"}, "outputs": [], "source": ["## Extract the second rule\n", "pprod_example = probabilistic_arithmetic_grammar.productions()[1]\n", "\n", "## Display its various components\n", "print(f'For the production \"{pprod_example}\":\\n' \n", "      f'left hand side of the rule is {pprod_example.lhs()}\\n'\n", "      f'right hand side of the rule is {pprod_example.rhs()}\\n'\n", "      f'probability of the rule is {pprod_example.prob()}')"]}, {"cell_type": "markdown", "id": "3d799a59", "metadata": {"colab_type": "text", "id": "Qx8sTaCVWIcg"}, "source": ["For non-probabilistic grammars, the class of productions is [Production](https://www.nltk.org/api/nltk.html?highlight=production#nltk.grammar.Production), which doesn't have a probability attribute and is only defined by its lhs and rhs attributes:"]}, {"cell_type": "code", "execution_count": null, "id": "85e6dabc", "metadata": {"colab": {}, "colab_type": "code", "id": "s67fRZjFXK4u"}, "outputs": [], "source": ["print(f'PCFG production: {probabilistic_arithmetic_grammar.productions()[1]} \\n'\n", "      f'      vs.\\n'\n", "      f'CFG production:  {arithmetic_grammar.productions()[1]}') "]}, {"cell_type": "markdown", "id": "a5c4f286", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "NTRVDqDjF18j"}, "source": ["# Parse tree probabilities\n", "\n", "To use a PCFG to select among parse trees, we need to be able to calculate the probability of a parse tree as specified by the PCFG. We take the probability of a parse tree to be simply the product of the probabilities of each constituent in the tree, the probability of the rule associated with the constituent.\n", "\n", "You'll use the PCFG `probabilistic_arithmetic_grammar` to calculate the probability of each of the parse trees in `parses`, the list of trees that were parsed from the `example` sentence. \n", "\n", "To do that, you'll need to get all the productions used in a parse tree (using the [productions](https://www.nltk.org/api/nltk.html?highlight=production#nltk.tree.Tree.productions) method), find their probabilities, and multiply them together.\n", "\n", "First, we will create a dictionary from the PCFG, so that we can easily access the rule probabilities. Write a function which accepts a PCFG and returns a dictionary whose keys are the CFG (not PCFG) productions and values are the associated probabilities. \n", "\n", "> To construct a CFG production from a PCFG production, you can use `nltk.grammar.Production(production.lhs(), production.rhs())`.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: pcfg_to_dict\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "12fdf868", "metadata": {"colab": {}, "colab_type": "code", "id": "wzrUO1KNuUz4"}, "outputs": [], "source": ["#TODO - returns a dictionary whose keys are `nltk.grammar.Production` objects\n", "#       and whose values are the associated probabilities\n", "def pcfg_to_dict(pcfg):\n", "  ..."]}, {"cell_type": "code", "execution_count": null, "id": "f51d5118", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"pcfg_to_dict\")"]}, {"cell_type": "markdown", "id": "bc248175", "metadata": {"colab_type": "text", "id": "1ImGQNeTHwRT"}, "source": ["We can use the function you wrote to convert `probabilistic_arithmetic_grammar` to a dictionary and inspect it to make sure it's working."]}, {"cell_type": "code", "execution_count": null, "id": "2c99dd64", "metadata": {}, "outputs": [], "source": ["pprint(pcfg_to_dict(probabilistic_arithmetic_grammar))"]}, {"cell_type": "markdown", "id": "bfc1fbe5", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "1ImGQNeTHwRT"}, "source": ["Now for the payoff: Write a function that takes a parse tree and a PCFG and returns the probability of the parse tree according to the PCFG. The `pcfg_to_dict` function you just wrote is likely to come in handy.\n", "\n", "> Note that we are asking for the probability (not the log probability). We **don't work in log space** in this lab for simplicity, but for parse trees of longer sentences (which you'll see in the project) you might have to work in the log space to avoid underflows.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parsed_trees_probs\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "7b0e4733", "metadata": {}, "outputs": [], "source": ["# TODO: returns the probability of the parse tree.\n", "# `tree.productions() might be useful for getting the \n", "#  productions of a parse tree\n", "def parse_probability(tree, pcfg):\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "id": "dac9ac2a", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parsed_trees_probs\")"]}, {"cell_type": "markdown", "id": "a0bdc06b", "metadata": {"colab_type": "text", "id": "1ImGQNeTHwRT"}, "source": ["We'll use it to calculate and print out the probability of each parse tree."]}, {"cell_type": "code", "execution_count": null, "id": "66ac6e01", "metadata": {}, "outputs": [], "source": ["for i, tree in enumerate(parses):\n", "    print(f'Probability of parse tree {i+1} is '\n", "          f'{parse_probability(tree, probabilistic_arithmetic_grammar):1.2e}')\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "id": "04deffae", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "h2F-sJGitFgs"}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "**Question:** Which of the trees is the most probable parse? Explain why. If the two have the same probability, explain why that is the case instead, and describe how you might adjust the rule probabilities if possible so that they have different probabilities.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_ambiguity\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "00b47ee1", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "7a29f1b6", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# Lexicalizing the grammar\n", "\n", "In order to allow parse probabilities to be more sensitive to contexts, it turns out to be useful to _lexicalize_ the grammar -- splitting (some of the) nonterminals based on what particular words they dominate. There are many techniques for performing this lexicalization. For this grammar, we'll split the `S` nonterminal based on the main operator that it dominates (if any). We'll thus have nonterminals `S_ADD`, `S_MULT`, and `S_NUM`. Thus, instead of a rule `S -> S OP S`, we'll have rules like:\n", "\n", "```\n", "S_ADD -> S_NUM ADD S_NUM\n", "S_ADD -> S_NUM ADD S_ADD\n", "S_ADD -> S_NUM ADD S_MULT\n", "S_ADD -> S_ADD ADD S_NUM\n", "``` \n", "and so forth. By splitting the nonterminals (and hence the productions) in this way, we can assign different probabilities to cases where, for instance, the primary operator on the left is a number, or addition, or multiplication.\n", "\n", "Here is the lexicalized grammar:"]}, {"cell_type": "code", "execution_count": null, "id": "154af9ec", "metadata": {}, "outputs": [], "source": ["lexicalized_arithmetic_grammar = nltk.CFG.fromstring( \n", "    \"\"\"\n", "    S -> S_NUM | S_ADD | S_MULT\n", "\n", "    S_NUM -> NUM\n", "\n", "    S_ADD -> S_NUM ADD S_NUM\n", "    S_ADD -> S_NUM ADD S_ADD\n", "    S_ADD -> S_NUM ADD S_MULT\n", "    S_ADD -> S_ADD ADD S_NUM\n", "    S_ADD -> S_ADD ADD S_ADD\n", "    S_ADD -> S_ADD ADD S_MULT\n", "    S_ADD -> S_MULT ADD S_NUM\n", "    S_ADD -> S_MULT ADD S_ADD\n", "    S_ADD -> S_MULT ADD S_MULT\n", "\n", "    S_MULT -> S_NUM MULT S_NUM\n", "    S_MULT -> S_NUM MULT S_ADD\n", "    S_MULT -> S_NUM MULT S_MULT\n", "    S_MULT -> S_ADD MULT S_NUM\n", "    S_MULT -> S_ADD MULT S_ADD\n", "    S_MULT -> S_ADD MULT S_MULT\n", "    S_MULT -> S_MULT MULT S_NUM\n", "    S_MULT -> S_MULT MULT S_ADD\n", "    S_MULT -> S_MULT MULT S_MULT\n", "\n", "    NUM -> 'zero'   | 'one'    | 'two'\n", "    NUM -> 'three'  | 'four'   | 'five'\n", "    NUM -> 'six'    | 'seven'  | 'eight'\n", "    NUM -> 'nine'   | 'ten'\n", "\n", "    ADD -> 'plus'\n", "    MULT -> 'times'\n", "    \"\"\" \n", ")"]}, {"cell_type": "markdown", "id": "7240c54c", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "Use this grammar to parse the example phrase (\"two plus three times four\") defined as `phrase` above.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: lexicalized_parse\n", "manual: true\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "612ae265", "metadata": {}, "outputs": [], "source": ["# TODO - parse `example` using the lexicalized grammar. `lexicalized_parses`\n", "#        should be a list of parses.\n", "lexicalized_parses = ..."]}, {"cell_type": "code", "execution_count": null, "id": "4ea3c21c", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"lexicalized_parse\")"]}, {"cell_type": "markdown", "id": "3a54f4a9", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "Examine the trees, and make sure that you understand why they look the way they do. Notice that because of the lexicalization, the highest `S_` node corresponds to the highest operator in the parse -- `S_MULT` when `MULT` is the highest operator and `S_ADD` when `ADD` is the highest operator."]}, {"cell_type": "code", "execution_count": null, "id": "213cdba5", "metadata": {}, "outputs": [], "source": ["for i, tree in enumerate(lexicalized_parses):\n", "  print(f\"Possible parse {i+1}:\\n\")\n", "  tree.pretty_print()"]}, {"cell_type": "markdown", "id": "320e701a", "metadata": {"deletable": false, "editable": false}, "source": ["We can augment this grammar with probabilities as well.\n", "\n", "Again, do so making the probabilities as uniform as possible.\n", "<!--\n", "BEGIN QUESTION\n", "name: uniform_lexicalized_probabilities\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "2b347154", "metadata": {}, "outputs": [], "source": ["# TODO - define `probabilistic_lexicalized_arithmetic_grammar`.\n", "#        Round to *3* significant figures if not divisible.\n", "probabilistic_lexicalized_arithmetic_grammar = nltk.PCFG.fromstring( \n", "    ...\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "c99cf088", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"uniform_lexicalized_probabilities\")"]}, {"cell_type": "markdown", "id": "8c22c0c1", "metadata": {}, "source": ["Using this PCFG, we can calculate the probabilities associated with the two parses of the example phrase."]}, {"cell_type": "code", "execution_count": null, "id": "42c06868", "metadata": {}, "outputs": [], "source": ["for i, tree in enumerate(lexicalized_parses):\n", "    print(f'Probability of parsed tree {i+1} is '\n", "          f'{parse_probability(tree, probabilistic_lexicalized_arithmetic_grammar):1.2e}')\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "id": "daf1278a", "metadata": {}, "source": ["Make sure that you understand why the parse probabilities are the way they are. Call over a staff member for a quick check."]}, {"cell_type": "markdown", "id": "6566ebc6", "metadata": {"colab_type": "text", "id": "q0LrzA8LvY0P"}, "source": ["# Estimating rule probabilities from a corpus\n", "\n", "In the previous section, you received a CFG augmented with rule probabilities that were arbitrarily stipulated. But where should rule probabilities come from? One way to generate rule probabilites is to learn them from a training corpus. \n", "\n", "In this section you will use a toy corpus of sentences parsed according to the lexicalized grammar to generate maximum likelihood estimates of rule probabilities by counting the number of occurrences of a rule used in the corpus."]}, {"cell_type": "code", "execution_count": null, "id": "f818179d", "metadata": {"colab": {}, "colab_type": "code", "id": "HCNGAEmtJkl3"}, "outputs": [], "source": ["## The raw corpus, before splitting into separate phrases\n", "corpus_raw = \"\"\"\n", "    # seven\n", "    (S (S_NUM (NUM seven)))\n", "    # one plus two\n", "    (S (S_ADD (S_NUM (NUM one)) (ADD plus) (S_NUM (NUM two))))\n", "    # two times three\n", "    (S (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))))\n", "    # two plus six times one\n", "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM six)) (MULT times) (S_NUM (NUM one)))))\n", "    # eight plus three plus seven\n", "    (S (S_ADD (S_ADD (S_NUM (NUM eight)) (ADD plus) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM seven))))\n", "    # two plus three times four\n", "    (S (S_ADD (S_NUM (NUM two)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM four)))))\n", "    # eight times four times two\n", "    (S (S_MULT (S_MULT (S_NUM (NUM eight)) (MULT times) (S_NUM (NUM four))) (MULT times) (S_NUM (NUM two))))\n", "    # five times two plus one\n", "    (S (S_ADD (S_MULT (S_NUM (NUM five)) (MULT times) (S_NUM (NUM two))) (ADD plus) (S_NUM (NUM one))))\n", "    # five plus one times four\n", "    (S (S_ADD (S_NUM (NUM five)) (ADD plus) (S_MULT (S_NUM (NUM one)) (MULT times) (S_NUM (NUM four)))))\n", "    # two times three plus four\n", "    (S (S_ADD (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_NUM (NUM four))))\n", "    # ten plus two times three\n", "    (S (S_ADD (S_NUM (NUM ten)) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM three)))))\n", "    # four times three plus two times one\n", "    (S (S_ADD (S_MULT (S_NUM (NUM four)) (MULT times) (S_NUM (NUM three))) (ADD plus) (S_MULT (S_NUM (NUM two)) (MULT times) (S_NUM (NUM one)))))\n", "    # four plus three times two plus one\n", "    (S (S_ADD (S_ADD (S_NUM (NUM four)) (ADD plus) (S_MULT (S_NUM (NUM three)) (MULT times) (S_NUM (NUM two)))) (ADD plus) (S_NUM (NUM one))))\n", "\"\"\"\n", "\n", "def corpus_from_string(raw):\n", "  \"\"\"Return a corpus as a list of sentences.\n", "  \n", "  The `raw` corpus is split at newlines, trimmed of whitespace, \n", "  and comment lines and blank lines are eliminated.\n", "  \"\"\"\n", "  return list(filter(lambda x: x != '' and x[0] != '#', \n", "                     map(lambda sent: sent.strip(),\n", "                         raw.split('\\n'))))\n", "\n", "## The processed corpus we'll use\n", "corpus = corpus_from_string(corpus_raw)"]}, {"cell_type": "markdown", "id": "906310dc", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "ep4DSx_F2Za3"}, "source": ["Recall that for the rule probabilities to define a valid probability distibution, the following needs to hold\n", "$$\\sum_{A \\to \\beta \\in G} \\Prob(\\beta \\given A) = 1$$\n", "where $G$ is the set of productions.\n", "\n", "In order to get an estimate for each production probability, we can count the number of occurrences of the production, normalizing by the number of occurrences of all productions with the same left-hand side.\n", "\n", "\\begin{align}\n", "\\Prob(\\beta \\given A) \n", "  &= \\frac{\\cnt{A \\to \\beta}}{\\sum_{\\beta'} \\cnt{A \\to \\beta'}} \\\\\n", "  &= \\frac{\\cnt{A \\to \\beta}}{\\cnt{A}}\n", "\\end{align}\n", "\n", "We will define three functions: \n", "\n", "1. `rule_counter` - accepts a list of sentences and returns a dictionary of rule counts (where the key is the NLTK CFG production (defined by the lhs and rhs) and the value is the number of rule occurrences)\n", "2. `lhs_counter` - accepts a list of sentences and returns a dictionary of lhs counts (where the key is the lhs nonterminal and the value is the count of that nonterminal's occurences as a lhs)\n", "3. `rule_probs` - accepts a list of sentences and returns a dictionary of rule probabilities (where the key is the production and the value is the rule probability).\n", "\n", "Implement these functions as specified above.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: probs_from_corpus\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "6e989154", "metadata": {"colab": {}, "colab_type": "code", "id": "iWRrTwp-wZOu"}, "outputs": [], "source": ["#TODO \n", "def rule_counter(sentence_list):\n", "  ...\n", "\n", "#TODO\n", "def lhs_counter(sentence_list):\n", "  ...\n", "\n", "#TODO\n", "def rule_probs(sentence_list):\n", "  ..."]}, {"cell_type": "code", "execution_count": null, "id": "a612b400", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"probs_from_corpus\")"]}, {"cell_type": "markdown", "id": "b94040d0", "metadata": {"colab_type": "text", "id": "sMEdd-KSg3J5"}, "source": ["Now we can use the `rules_prob` function you wrote to get the rule probabilities from our corpus:"]}, {"cell_type": "code", "execution_count": null, "id": "7b157150", "metadata": {"colab": {}, "colab_type": "code", "id": "Q0TCm-8vgOAR"}, "outputs": [], "source": ["probs_from_corpus = rule_probs(corpus)\n", "pprint(probs_from_corpus)"]}, {"cell_type": "markdown", "id": "07f69fe2", "metadata": {"colab_type": "text", "id": "VofTcEId8Y-n"}, "source": ["Observe that the probabilities of the two rules `S_ADD -> S_NUM ADD S_MULT` and `S_MULT -> S_ADD MULT S_NUM` are now different from each other. (They were both the same in the previous grammar, since you made the probabilities as uniform as possible.)\n", "\n", "NLTK allows us to infer a probabilistic grammar from a parsed corpus like this one using [`nltk.induce_pcfg`](https://www.nltk.org/api/nltk.grammar.html#nltk.grammar.induce_pcfg). Let's do that."]}, {"cell_type": "code", "execution_count": null, "id": "7fb43a37", "metadata": {}, "outputs": [], "source": ["def flatten(l):\n", "    return sum(l, [])\n", "    \n", "def pcfg_from_trees(trees):\n", "    return nltk.induce_pcfg(nltk.Nonterminal('S'), \n", "                            flatten([nltk.Tree.fromstring(tree).productions() \n", "                                     for tree in trees]))\n", "\n", "induced_pcfg = pcfg_from_trees(corpus)\n", "\n", "print(induced_pcfg)"]}, {"cell_type": "markdown", "id": "4a57abe5", "metadata": {}, "source": ["We'll use NLTK's implementation of the probabilistic CKY algorithm ([`nltk.ViterbiParser`](https://www.nltk.org/api/nltk.parse.viterbi.html#nltk.parse.viterbi.ViterbiParser)) to generate the best parse for some strings according to this induced PCFG. (You'll implement this yourself in lab 3-4.)"]}, {"cell_type": "code", "execution_count": null, "id": "b0fd1fbe", "metadata": {}, "outputs": [], "source": ["induced_parser = nltk.ViterbiParser(induced_pcfg)"]}, {"cell_type": "markdown", "id": "7808fd40", "metadata": {"deletable": false, "editable": false}, "source": ["Use this parser to parse the `example` phrase \"two plus three times four\" from above. Which parse does it return? Do you understand why?\n", "\n", "> Be careful. The parser returns a Python generator of the parses, not a list. You can't use the generator twice, so you should save the `induced_grammar_parses` as a list constructed from the generator object to pass all of the tests.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: induced_grammar_parses\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "ddcfd95d", "metadata": {}, "outputs": [], "source": ["# TODO - parse `example` using `induced_parser`\n", "induced_grammar_parses = ..."]}, {"cell_type": "code", "execution_count": null, "id": "986b65d2", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"induced_grammar_parses\")"]}, {"cell_type": "code", "execution_count": null, "id": "a6aed174", "metadata": {}, "outputs": [], "source": ["for i, tree in enumerate(induced_grammar_parses):\n", "    print(f'Probability of parse tree {i+1} is '\n", "          f'{parse_probability(tree, induced_pcfg):1.2e}')\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "id": "d586987a", "metadata": {}, "source": ["Now consider a new example:"]}, {"cell_type": "code", "execution_count": null, "id": "b303edab", "metadata": {}, "outputs": [], "source": ["example2 = \"three plus nine plus two\""]}, {"cell_type": "markdown", "id": "e5059ee8", "metadata": {"deletable": false, "editable": false}, "source": ["How many parses there are for this new expression \"three plus nine plus two\" according to the induced PCFG? Set the variable in the next cell accordingly.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: parse_count_2\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "1226af2a", "metadata": {}, "outputs": [], "source": ["# TODO \n", "example2_parse_count = ..."]}, {"cell_type": "code", "execution_count": null, "id": "2ea34bac", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"parse_count_2\")"]}, {"cell_type": "markdown", "id": "01feb8a7", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "**Question:** You undoubtedly obtained a number of parses for this second example that didn't seem appropriate. With a _single word_, what technique that you've learned would be appropriate to solve this problem.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "3d613e04", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "1f010fdd", "metadata": {"colab_type": "text", "deletable": false, "editable": false, "id": "h2F-sJGitFgs"}, "source": ["<!-- END QUESTION -->\n", "\n", "<!-- BEGIN QUESTION -->\n", "\n", "**Question:** The example that we provided of an ambiguity in arithmetic expressions is admittedly quite artificial. Can you think of other (more natural) examples, in natural language or elsewhere, where this phenomenon might occur?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_other_examples\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "583ec80a", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "ff1cf9bc", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- END QUESTION -->\n", "\n", "<!-- BEGIN QUESTION -->\n", "\n", "# Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "d4a45486", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "99324f75", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of Lab 3-3 {-}"]}, {"cell_type": "markdown", "id": "fcf56caa", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "id": "7436ddfe", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"colab": {"collapsed_sections": [], "name": "lab3-3_op3.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}, "title": "CS187 Lab 3-3: Probabilistic context-free grammars"}, "nbformat": 4, "nbformat_minor": 5}